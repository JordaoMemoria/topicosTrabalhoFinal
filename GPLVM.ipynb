{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "periodic-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import gpflow\n",
    "from gpflow.utilities import ops, print_summary\n",
    "from gpflow.config import set_default_float, default_float, set_default_summary_fmt\n",
    "from gpflow.ci_utils import ci_niter\n",
    "\n",
    "set_default_float(np.float64)\n",
    "set_default_summary_fmt(\"notebook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chief-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('housesToRentProcessed.csv', index_col=0)\n",
    "\n",
    "X = dataset[[\n",
    "    'São Paulo', 'Porto Alegre', 'Rio de Janeiro', 'Campinas', 'Belo Horizonte', \n",
    "    'area',\n",
    "    'rooms', 'bathroom', 'parking spaces', 'floor', 'isHouse', 'animal', 'furniture',\n",
    "]].values\n",
    "y = dataset[['y con + alu']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "knowing-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "cidade = dataset[['São Paulo', 'Porto Alegre', 'Rio de Janeiro', 'Campinas', 'Belo Horizonte']]\n",
    "cidade = cidade * (1, 2, 3, 4, 5)\n",
    "cidade = cidade.sum(axis=1) - 1\n",
    "cidade = cidade.values.reshape((-1, 1))\n",
    "\n",
    "labels = tf.convert_to_tensor(cidade, dtype=default_float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "processed-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.convert_to_tensor(X, dtype=default_float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "pretty-entrance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 10688 and Number of dimensions: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of points: {} and Number of dimensions: {}\".format(Y.shape[0], Y.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "scheduled-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2  # number of latent dimensions\n",
    "num_inducing = 20  # number of inducing pts\n",
    "num_data = Y.shape[0]  # number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "induced-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean_init = ops.pca_reduce(Y, latent_dim)\n",
    "X_var_init = tf.ones((num_data, latent_dim), dtype=default_float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sapphire-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)  # for reproducibility\n",
    "inducing_variable = tf.convert_to_tensor(\n",
    "    np.random.permutation(X_mean_init.numpy())[:num_inducing], dtype=default_float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cooperative-jones",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float64, numpy=-4.600266525158521>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengthscales = tf.convert_to_tensor([1.0] * latent_dim, dtype=default_float())\n",
    "kernel = gpflow.kernels.RBF(lengthscales=lengthscales)\n",
    "\n",
    "gplvm = gpflow.models.BayesianGPLVM(\n",
    "    Y,\n",
    "    X_data_mean=X_mean_init,\n",
    "    X_data_var=X_var_init,\n",
    "    kernel=kernel,\n",
    "    inducing_variable=inducing_variable,\n",
    ")\n",
    "# Instead of passing an inducing_variable directly, we can also set the num_inducing_variables argument to an integer, which will randomly pick from the data.\n",
    "\n",
    "gplvm.likelihood.variance.assign(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = gpflow.optimizers.Scipy()\n",
    "maxiter = ci_niter(1000)\n",
    "_ = opt.minimize(\n",
    "    gplvm.training_loss,\n",
    "    method=\"BFGS\",\n",
    "    variables=gplvm.trainable_variables,\n",
    "    options=dict(maxiter=maxiter),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary(gplvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = ops.pca_reduce(Y, latent_dim).numpy()\n",
    "gplvm_X_mean = gplvm.X_data_mean.numpy()\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "for i in np.unique(labels):\n",
    "    ax[0].scatter(X_pca[labels == i, 0], X_pca[labels == i, 1], label=i)\n",
    "    ax[1].scatter(gplvm_X_mean[labels == i, 0], gplvm_X_mean[labels == i, 1], label=i)\n",
    "    ax[0].set_title(\"PCA\")\n",
    "    ax[1].set_title(\"Bayesian GPLVM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
